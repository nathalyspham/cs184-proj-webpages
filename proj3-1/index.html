<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<style>
  body {
    background-color: white;
    padding: 100px;
    width: 1000px;
    margin: auto;
    text-align: left;
    font-weight: 300;
    font-family: 'Open Sans', sans-serif;
    color: #121212;
  }
  h1, h2, h3, h4 {
    font-family: 'Source Sans Pro', sans-serif;
  }
  kbd {
    color: #121212;
  }
</style>
<title>CS 184 Path Tracer</title>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro" rel="stylesheet">

<script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']]
    }
  };
</script>
<script id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
</script>

</head>


<body>

<h1 align="middle">CS 184: Computer Graphics and Imaging, Spring 2023</h1>
<h1 align="middle">Project 3-1: Path Tracer</h1>
<h2 align="middle">Kehan Li and Nathalys Pham</h2>

<!-- Add Website URL -->
<h2 align="middle">Website URL: <a href="https://nathalyspham.github.io/cs184-proj-webpages/proj3-1/index.html">Website link</a></h2>

<br><br>
<!-- 

<div align="center">
  <table style="width=100%">
      <tr>
          <td align="middle">
          <img src="images/example_image.png" width="480px" />
          <figcaption align="middle">Results Caption: my bunny is the bounciest bunny</figcaption>
      </tr>
  </table>
</div>

<p>All of the text in your write-up should be <em>in your own words</em>. If you need to add additional HTML features to this document, you can search the <a href="http://www.w3schools.com/">http://www.w3schools.com/</a> website for instructions. To edit the HTML, you can just copy and paste existing chunks and fill in the text and image file names appropriately.</p>
<o>The website writeup is intended to be a self-contained walkthrough of the assignment: we want this to be a piece of work which showcases your understanding of relevant concepts through both mesh images as well as written explanations about what you did to complete each part of the assignment. Try to be as clear and organized as possible when writing about your own output files or extensions to the assignment. We want to understand what you've achieved and how you've done it!</p> 
<p>If you are well-versed in web development, feel free to ditch this template and make a better looking page.</p>


<p>Here are a few problems students have encountered in the past. Test your website on the instructional machines early!</p>
<ul>
<li>Your main report page should be called index.html.</li>
<li>Be sure to include and turn in all of the other files (such as images) that are linked in your report!</li>
<li>Use only <em>relative</em> paths to files, such as <pre>"./images/image.jpg"</pre>
Do <em>NOT</em> use absolute paths, such as <pre>"/Users/student/Desktop/image.jpg"</pre></li>
<li>Pay close attention to your filename extensions. Remember that on UNIX systems (such as the instructional machines), capitalization matters. <pre>.png != .jpeg != .jpg != .JPG</pre></li>
<li>Be sure to adjust the permissions on your files so that they are world readable. For more information on this please see this tutorial: <a href="http://www.grymoire.com/Unix/Permissions.html">http://www.grymoire.com/Unix/Permissions.html</a></li>
<li>And again, test your website on the instructional machines early!</li>
</ul>


<p>Here is an example of how to include a simple formula:</p>
<p align="middle"><pre align="middle">a^2 + b^2 = c^2</pre></p>
<p>or, alternatively, you can include an SVG image of a LaTex formula.</p>

<div> -->

<h2 align="middle">Overview</h2>
<p>
In this assignment we implemented ray tracing algorithms to render scenes. In part 1, we first worked on generating rays from a coordinate in an image to world space and pixel samples. 
Then we implemented primitive intersection algorithm which finds the intersection between a ray and a shape. In part 2 implemented the BVH to speed up our path tracer to identifying intersections. This was an important part of our project as we realized without a proper implementation here, all other parts are rendered significantly slowly. 
In part 3 we implemented direct illumination by calculating zero-bounce and one-bounce radiance. In part 4, we calcualted the indirect radiance by recursion to simulate the effect light bouncing off objects. The combination of direct and indirect illumination allowed us to render realistic shading for the models. 
Lastly in part 5 we implemented importance sampling to sample more in areas where there are more changes in the radiance thus reducing noise in our rendered images. Together, in this assignment we are able to use ray-tracing algorithms to efficiently render images with realistic illumination. 
</p>
<br>

<h2 align="middle">Part 1: Ray Generation and Scene Intersection (20 Points)</h2>
<!-- Walk through the ray generation and primitive intersection parts of the rendering pipeline.
Explain the triangle intersection algorithm you implemented in your own words.
Show images with normal shading for a few small .dae files. -->

<h3>
  Walk through the ray generation and primitive intersection parts of the rendering pipeline.
</h3>
<p>
I generated the ray by calculating where it should be on the image frame. We know that the ray starts as pos, which is the position of the camera. Then we just need to calculate the direction to generate the ray. To do this, first I subtracted -0.5 from x and y so that the frame is centered at (0,0). Then I found the relative position of x and y in camera space by multiplying them by 2*tan(hFov)/2 and 2*tan(vFov)/2, respectively. I constructed a vector with the new(x, y, -1),  then multiplied it by the camera to world matrix and normalized it, and let this vector be v. This was the desired direction vector. So I returned Ray(pos, v) and also set the min_t and max_t of the ray.  
</p>
<p>
For the primitive intersection part of the pipeline, if we do not intersect with a given object (triangle or sphere) we simply return false, otherwise, we can find information about the intersection and we set all the attributes of this intersection such as it’s time, normal, and primitive and return the intersection.
</p>
<br>

<h3>
  Explain the triangle intersection algorithm you implemented in your own words.
</h3>
<p>
  On a higher level, I achieved this by first detecting whether the ray intersects with the plane of the triangle, then using barycentric coordinates to find whether the point of intersection is within the triangle. But this was achieved in a simple fashion through the Möller–Trumbore algorithm. We closely followed the equations on the lecture slides to implement this algorithm.
</p>
<div align="center">
  <table style="width=100%">
      <tr>
          <td align="middle">
          <img src="images/triangle_q.png" width="480px" />
          <figcaption align="middle">The Möller–Trumbore algorithm </figcaption>
      </tr>
  </table>
</div>
<p>
  Then, we check that t_min<=t<=t_max, which shows that the ray intersects with the plane. We also check that 0<=b1<=1, 0<=b2<=1, 0<=(1-b1-b2)<=1, this checks whether each barycentric coordinate of the interpolated point is valid such that the pointer is inside the triangle. Hence if all these conditions are met, we can return true, meaning that the ray did intersect the triangle. Otherwise we return false because either the ray didn't intersect with the plane or intersected the plane on a point outside of the triangle. 
</p>


<br>

<h3>
  Show images with normal shading for a few small .dae files.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/1_empty.png" align="middle" width="400px"/>
        <figcaption>CBempty.dae</figcaption>
      </td>
      <td>
        <img src="images/1_spheres.png" align="middle" width="400px"/>
        <figcaption>CBspheres_lambertian.dae</figcaption>
      </td>
    </tr>
    <!-- <tr align="center">
      <td>
        <img src="images/your_file.png" align="middle" width="400px"/>
        <figcaption>example3.dae</figcaption>
      </td>
      <td>
        <img src="images/your_file.png" align="middle" width="400px"/>
        <figcaption>example4.dae</figcaption>
      </td>
    </tr> -->
  </table>
</div>
<br>


<h2 align="middle">Part 2: Bounding Volume Hierarchy (20 Points)</h2>
<!-- Walk through your BVH construction algorithm. Explain the heuristic you chose for picking the splitting point.
Show images with normal shading for a few large .dae files that you can only render with BVH acceleration.
Compare rendering times on a few scenes with moderately complex geometries with and without BVH acceleration. Present your results in a one-paragraph analysis. -->

<h3>
  Walk through your BVH construction algorithm. Explain the heuristic you chose for picking the splitting point.
</h3>
<p>
  In BVHAccel:construct_bvh(...), my first heuristic was to split based on the primitives’ median. I found the largest range on each axis and sorted based on that, and then, I took the median as the split point. This didn’t work because I had trouble manipulating the iterators using sort(...). Then, I tried to use a naive approach of splitting along the center of each axis, but this approach was very slow because I wouldn’t get an even split of primitives on each side. My final algorithm was to find the mean of the largest axis and use partition(...) to split on the mean. In the base case, if a box had <= the max number allowed, I would return a node with all the primitives. Otherwise, I would call construct_bvh(...) recursively to make the left child with all the items less the mean and the right child with all the items greater than the mean. I came across a problem with infinite recursion here. If all the primitives were on one side of a split and the box had too many items, the recursive call would call with the same arguments again, and I solved this issue by just adding or subtracting from the splitPoint if it was equal to start or end.
  In BBox::intersect(...), I used lecture and discussion 5 to help me calculate the t values. I calculated the t values at the min and max locations of intersection for each axis, and then I took the max of the tmins and the min of the tmaxs in order to get the ts that correspond to the intersection of the entire box. 
  In BVHAccel::intersect(...) and BVHAccel::has_intersection(...), everything came together. I followed the pseudocode from lecture to make the BVH recursive algorithm and find the closest intersection. If the ray doesn’t intersect the box at all, I just return false since the ray cannot intersect any primitives in the box. Then, if the ray and box intersect, I recursively call and check for intersections in the box’s left and right children. Once I reach a leaf node that the ray intersects, I iterate over all the primitives and check for intersections between the primitive and the ray.  
</p>

<h3>
  Show images with normal shading for a few large .dae files that you can only render with BVH acceleration.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/lucy_bvh.png" align="middle" width="350px"/>
        <figcaption>CBlucy.dae</figcaption>
      </td>
      <td>
        <img src="images/planck_bvh.png" align="middle" width="350px"/>
        <figcaption>maxplanck.dae</figcaption>
      </td>
      <td>
        <img src="images/dragon_bvh.png" align="middle" width="350px"/>
        <figcaption>dragon.dae</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>

<h3>
  Compare rendering times on a few scenes with moderately complex geometries with and without BVH acceleration. Present your results in a one-paragraph analysis.
</h3>
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/cow_bvh.png" align="middle" width="400px"/>
        <img src="images/cow_time.png" align="middle" width="400px"/>
        <figcaption>cow.dae before bvh</figcaption>
      </td>
      <td>
        <img src="images/cow_bvh.png" align="middle" width="400px"/>
        <img src="images/cow_bvh_time.png" align="middle" width="400px"/>
        <figcaption>cow.dae after bvh</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/planck_bvh.png" align="middle" width="400px"/>
        <img src="images/planck_time.png" align="middle" width="400px"/>
        <figcaption>maxplanck.dae before bvh</figcaption>
      </td>
      <td>
        <img src="images/planck_bvh.png" align="middle" width="400px"/>
        <img src="images/planck_bvh_time.png" align="middle" width="400px"/>
        <figcaption>maxplanck.dae after bvh</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>

<p>
  With my final heuristic, the speedup was crazy. First, cow is a relatively small file, so it only took 3 seconds to render without speedup, but after bvh acceleration, it only took 0.03 seconds, which is ~100x faster! Without bvh acceleration, maxplanck took 55 seconds, and with bvh, it only took 0.05 seconds which is ~1000x faster. For larger files like maxplanck, bvh acceleration is even more efficient because you always have to go through the same overhead of constructing a bvh tree and all the checks and recursion regardless of the size of the file, but larger files will use the tree more times. For very small files, bvh acceleration might even be slower because of the extra checks. The difference between with and without bvh is also greater in larger files because you are skipping more triangles since you are dividing by two at each level and are only looking at a logarithmic amount of the triangles. With bvh acceleration, there are also less rays traced by bvh, more rays per second, and less intersection tests per ray. We don’t have to check intersections between the ray and every single primitive, which means less intersection tests and rays that need to be traced.
</p>

<h2 align="middle">Part 3: Direct Illumination (20 Points)</h2>
<!-- Walk through both implementations of the direct lighting function.
Show some images rendered with both implementations of the direct lighting function.
Focus on one particular scene with at least one area light and compare the noise levels in soft shadows when rendering with 1, 4, 16, and 64 light rays (the -l flag) and with 1 sample per pixel (the -s flag) using light sampling, not uniform hemisphere sampling.
Compare the results between uniform hemisphere sampling and lighting sampling in a one-paragraph analysis. -->

<h3>
  Walk through both implementations of the direct lighting function.
</h3>
<p>
  First, we had to calculate the diffuse lambertian bsdf, and then, we calculated zero-bounce radiance, which is just the emission of the bsdf. Then, for one-bounce radiance, we used the Monte Carlo Estimator. We first did estimate_direct_lighting_hemisphere(...) where we sampled uniformly on a hemisphere. We used hemisphereSampler->get_sample(...) to get a sample. Then, we made a ray from hit_p to the sample. Next, we check if bvh intersects the ray, and if it does, add f(...) * L(...) * cos(...) / p(...) to the output. I had a hard time figuring out the pdf at first, but I just thought of what the probability of sampling on a uniform hemisphere was. Finally, we divided by the number of samples in the end. In estimate_direct_lighting_importance(...), we estimated the lighting from an intersection coming directly from a light. We iterated over all the lights in the scene and then took samples using SceneLight::sample_L(...) which fills wi, distToLight, and pdf. Now, we make a ray from hit_p to wi. If bvh does not intersect the ray, we add f(...) * L(...) * cos(...) / p(...) to the output, and we now use the newly populated wi and pdf. Finally, we divided by the number of samples.
</p>

<h3>
  Show some images rendered with both implementations of the direct lighting function.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <!-- Header -->
    <tr align="center">
      <th>
        <b>Uniform Hemisphere Sampling</b>
      </th>
      <th>
        <b>Light Sampling</b>
      </th>
    </tr>
    <br>
    <tr align="center">
      <td>
        <img src="images/CBspheres_lambertian_64_32_hemisphere.png" align="middle" width="400px"/>
        <figcaption>CBspheres.dae</figcaption>
      </td>
      <td>
        <img src="images/CBspheres_lambertian_64_32_importance.png" align="middle" width="400px"/>
        <figcaption>CBspheres.dae</figcaption>
      </td>
    </tr>
    <br>
    <tr align="center">
      <td>
        <img src="images/CBbunny_H_16_8_hemisphere.png" align="middle" width="400px"/>
        <figcaption>CBbunny.dae</figcaption>
      </td>
      <td>
        <img src="images/CBbunny_H_16_8_importance.png" align="middle" width="400px"/>
        <figcaption>CBbunny.dae</figcaption>
      </td>
    </tr>
    <br>
  </table>
</div>
<br>

<h3>
  Focus on one particular scene with at least one area light and compare the noise levels in <b>soft shadows</b> when rendering with 1, 4, 16, and 64 light rays (the -l flag) and with 1 sample per pixel (the -s flag) using light sampling, <b>not</b> uniform hemisphere sampling.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/CBbunny_H_16_8_importance_1.png" align="middle" width="200px"/>
        <figcaption>1 Light Ray (CBbunny.dae)</figcaption>
      </td>
      <td>
        <img src="images/CBbunny_H_16_8_importance_4.png" align="middle" width="200px"/>
        <figcaption>4 Light Rays (CBbunny.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/CBbunny_H_16_8_importance_16.png" align="middle" width="200px"/>
        <figcaption>16 Light Rays (CBbunny.dae)</figcaption>
      </td>
      <td>
        <img src="images/CBbunny_H_16_8_importance_64.png" align="middle" width="200px"/>
        <figcaption>64 Light Rays (CBbunny.dae)</figcaption>
      </td>
    </tr>
  </table>
</div>

<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/wall-e_H_16_8_importance_1.png" align="middle" width="200px"/>
        <figcaption>1 Light Ray (wall-e.dae)</figcaption>
      </td>
      <td>
        <img src="images/wall-e_H_16_8_importance_4.png" align="middle" width="200px"/>
        <figcaption>4 Light Rays (wall-e.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/wall-e_H_16_8_importance_16.png" align="middle" width="200px"/>
        <figcaption>16 Light Rays (wall-e.dae)</figcaption>
      </td>
      <td>
        <img src="images/wall-e_H_16_8_importance_64.png" align="middle" width="200px"/>
        <figcaption>64 Light Rays (wall-e.dae)</figcaption>
      </td>
    </tr>
  </table>
</div>
<p>
  The lower the number of light rays, the more noise there is. The -l 1 images have very distinct spots obscuring the image, and there is no clear or gradient shading. In comparison, the -l 64 images have more intermediate values and smoother shading. This is because with more rays we are able to get a better estimate of the true average, as we are averaging over more samples of light rays. 
</p>
<br>

<h3>
  Compare the results between uniform hemisphere sampling and lighting sampling in a one-paragraph analysis.
</h3>
<p>
  The results from hemisphere sampling were a lot more noisy and included more dark spots. You can see this in the above images. In the bunny image, the edge between the back wall and the ceiling is not straight. There are not smooth blends anywhere. These problems can also be seen with the spheres. This is because when we use uniform hemisphere sampling, we are using uniform random samples from ANYWHERE on the hemisphere, so we are likely to hit spots that are not the light source. And this makes only a small proportion of the random samples contribute to the overall light
</p>
<br>


<h2 align="middle">Part 4: Global Illumination (20 Points)</h2>
<!-- Walk through your implementation of the indirect lighting function.
Show some images rendered with global (direct and indirect) illumination. Use 1024 samples per pixel.
Pick one scene and compare rendered views first with only direct illumination, then only indirect illumination. Use 1024 samples per pixel. (You will have to edit PathTracer::at_least_one_bounce_radiance(...) in your code to generate these views.)
For CBbunny.dae, compare rendered views with max_ray_depth set to 0, 1, 2, 3, and 100 (the -m flag). Use 1024 samples per pixel.
Pick one scene and compare rendered views with various sample-per-pixel rates, including at least 1, 2, 4, 8, 16, 64, and 1024. Use 4 light rays.
You will probably want to use the instructional machines for the above renders in order to not burn up your own computer for hours. -->

<h3>
  Walk through your implementation of the indirect lighting function.
</h3>
<p>
  We implemented at_least_one_bounce_radiance with recursion. We utilized Russian roulette to eventually terminate the algorithm, with a termination probability of 0.3. During one recursive call, we first get L_out calling one_bounce_radiance. Then if coin_flip(0.7) is true, we continue with the recursion otherwise we just return L_out. If we decide we will continue the recursion, we first get a new sample from the bsdf with w_out. Then when generating a new ray next_r with the return wi_d. We set the depth of this ray as the depth of the current ray -1 and the min_t of the next ray as EPS_F. We calculate the cos theta as the dot product of the normal of the intersection and wi_d multiplied by the object-to-world matrix. Then if next_r’s depth is still >= 1, and bvh->intersect(next_r,&next_i) returns true, we continue with the recursion. In that case, we find the return value of the next_ray and a new intersection, let this value be r_recursed. Then finally we add this to L_out as  r_recursed * sample from bsdf * cos theta/ pdf from bsdf / 0.7 and return L_out in the end. The implemention mostly followed this slide from lecture. 
</p>
<div align="center">
  <table style="width=100%">
      <tr>
          <td align="middle">
          <img src="images/pseudocode.png" width="480px" />
          <figcaption align="middle">Pseudocode from Lecture </figcaption>
      </tr>
  </table>
</div>
  <p>
  Then, we implemented est_radiance_global_illumination to account for direct and indirect illustration. Hence we return L_out as the sum of values returned by zero_bound_randiance +at_least_one_bounce_radiance which are the direct (zero- and one- time bounce) and indirect (more than one-time bounce) illumination radiance summed.   
</p>
<br>

<h3>
  Show some images rendered with global (direct and indirect) illumination. Use 1024 samples per pixel.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/1024_bunny.png" align="middle" width="400px"/>
        <figcaption>CBbunny.dae</figcaption>
      </td>
      <td>
        <img src="images/1024_dragon.png" align="middle" width="400px"/>
        <figcaption>dragon.dae</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>

<h3>
  Pick one scene and compare rendered views first with only direct illumination, then only indirect illumination. Use 1024 samples per pixel. (You will have to edit PathTracer::at_least_one_bounce_radiance(...) in your code to generate these views.)
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/spheres_direct.png" align="middle" width="400px"/>
        <figcaption>Only direct illumination (CBspheres_lambertian.dae)</figcaption>
      </td>
      <td>
        <img src="images/spheres_indirect.png" align="middle" width="400px"/>
        <figcaption>Only indirect illumination (CBspheres_lambertian.dae)</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>
<p>
It may be seen in that in the image generated with only direct illumination, only the faces of facing the light source and the light source itself are lit up as direct illumination is only the zero time and once time bounce. The indirect image is really interesting as it seems as if there are light sources placed everywhere, but this is because the indirect case shows the light resulting from bounces that are not the first one so it looks like it came from many directions.  
</p>
<br>

<h3>
  For CBbunny.dae, compare rendered views with max_ray_depth set to 0, 1, 2, 3, and 100 (the -m flag). Use 1024 samples per pixel.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/bunny_d_0.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 0 (CBbunny.dae)</figcaption>
      </td>
      <td>
        <img src="images/bunny_d_1.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 1 (CBbunny.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/bunny_d_2.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 2 (CBbunny.dae)</figcaption>
      </td>
      <td>
        <img src="images/bunny_d_3.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 3 (CBbunny.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/bunny_d_100.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 100 (CBbunny.dae)</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>
<p>
It may be seen that having more ray-depth resulted in images that are brighter in general. This is because the rays are able to be traced further by the algorithm, bouncing off more times and increasing radiance accumulated in the process. The change as max_ray_depth increase is quite significant and visible when max_ray_depth is small. 
</p>
<br>

<h3>
  Pick one scene and compare rendered views with various sample-per-pixel rates, including at least 1, 2, 4, 8, 16, 64, and 1024. Use 4 light rays.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/bunny_s_1.png" align="middle" width="400px"/>
        <figcaption>1 sample per pixel (CBbunny.dae)</figcaption>
      </td>
      <td>
        <img src="images/bunny_s_2.png" align="middle" width="400px"/>
        <figcaption>2 samples per pixel (CBbunny.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/bunny_s_4.png" align="middle" width="400px"/>
        <figcaption>4 samples per pixel (CBbunny.dae)</figcaption>
      </td>
      <td>
        <img src="images/bunny_s_8.png" align="middle" width="400px"/>
        <figcaption>8 samples per pixel (CBbunny.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/bunny_s_16.png" align="middle" width="400px"/>
        <figcaption>16 samples per pixel (CBbunny.dae)</figcaption>
      </td>
      <td>
        <img src="images/bunny_s_64.png" align="middle" width="400px"/>
        <figcaption>64 samples per pixel (CBbunny.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/bunny_s_1024.png" align="middle" width="400px"/>
        <figcaption>1024 samples per pixel (CBbunny.dae)</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>
<p>
It may be noticed that as the number of samples increased the image became more smooth and there was less noise, it created way more realistic renderings. However the time to render also increased greatly as sample per pixel increased. 
</p>
<br>


<h2 align="middle">Part 5: Adaptive Sampling (20 Points)</h2>
<!-- Explain adaptive sampling. Walk through your implementation of the adaptive sampling.
Pick one scene and render it with at least 2048 samples per pixel. Show a good sampling rate image with clearly visible differences in sampling rate over various regions and pixels. Include both your sample rate image, which shows your how your adaptive sampling changes depending on which part of the image you are rendering, and your noise-free rendered result. Use 1 sample per light and at least 5 for max ray depth. -->

<h3>
  Explain adaptive sampling. Walk through your implementation of the adaptive sampling.
</h3>
<p>
  Adaptive sampling detects whether a pixel has converged as we trace ray samples through it. Through this, it reduces noise in the ray-traced image as it concentrates on sampling in more difficult parts of the image so it doesn't sample the same for each pixel. Our implementation closely follows the formula given in the spec. Within every loop of sampling, we now check if loop i modular samplesperbatch is = 0 because then we need to check for convergence. To check for convergence, we calculate the standard division and mean using s1 and s2 variables which we tracked during the sampling loop. From there, we calculated I=1.96*std/(current number of loops completed) and checked whether I<=maxTolerance*mean, if this is true, we break out of the loop because we have “converged” already and don’t need to sample further here, otherwise the loop continues as usual. 
</p>
<br>

<h3>
  Pick two scenes and render them with at least 2048 samples per pixel. Show a good sampling rate image with clearly visible differences in sampling rate over various regions and pixels. Include both your sample rate image, which shows your how your adaptive sampling changes depending on which part of the image you are rendering, and your noise-free rendered result. Use 1 sample per light and at least 5 for max ray depth.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/2048_bunny.png" align="middle" width="400px"/>
        <figcaption>Rendered image (CBbunny.dae)</figcaption>
      </td>
      <td>
        <img src="images/2048_bunny_rate.png" align="middle" width="400px"/>
        <figcaption>Sample rate image (CBbunny.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/2048_dragon.png" align="middle" width="400px"/>
        <figcaption>Rendered image (dragon.dae)</figcaption>
      </td>
      <td>
        <img src="images/2048_dragon_rate.png" align="middle" width="400px"/>
        <figcaption>Sample rate image (dragon.dae)</figcaption>
      </td>
    </tr>
  </table>
</div>
<p>
  It may be seen that after implementing task 5, the sample rate is a lot larger in places with more change in radiance whereas areas where the light is more consistent is sampled a lot less. This demonstrates the effectivness of adaptive sampling in reducing the number of samples in some areas and hence reducing noise in the rendered image. 
</p>
<br>


</body>
</html>
