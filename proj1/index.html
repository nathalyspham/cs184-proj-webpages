<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<style>
  body {
    padding: 100px;
    width: 1000px;
    margin: auto;
    text-align: left;
    font-weight: 300;
    font-family: 'Open Sans', sans-serif;
    color: #121212;
  }
  h1, h2, h3, h4 {
    font-family: 'Source Sans Pro', sans-serif;
  }
</style>
<title>CS 184 Rasterizer</title>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro" rel="stylesheet">
</head>


<body>

<h1 align="middle">CS 184: Computer Graphics and Imaging, Spring 2018</h1>
<h1 align="middle">Project 1: Rasterizer</h1>
<h2 align="middle">Kehan Li and Nathalys Pham, CS184</h2>

<br><br>

<div>

<h2 align="middle">Overview</h2>
<p>In this project, we implemented various image processing techniques that allowed us to draw shapes, transform shapes, and produce anti-aliasing results. With the methods that we have implemented, we are able to draw triangles with the least amount of aliasing, map images to a different texture, and transform shapes to different orientations. With this, we can produce a range of interesting visual effects. We were definitely able to understand the process of super-sampling, mipmapping, and barycentric coordinates better through this project. It was interesting to see how versatile barycentric coordinates are for interpolating different colors and textures. </p>

<h2 align="middle">Section I: Rasterization</h2>

<h3 align="middle">Part 1: Rasterizing single-color triangles</h3>

<!-- <p>Here is an example 2x2 gridlike structure using an HTML table. Each <b>tr</b> is a row and each <b>td</b> is a column in that row. You might find this useful for framing and showing your result images in an organized fashion.</p>

<div align="middle">
  <table style="width=100%">
    <tr>
      <td>
        <img src="images/image1.png" align="middle" width="400px"/>
        <figcaption align="middle">Caption goes here.</figcaption>
      </td>
      <td>
        <img src="images/image2.png" align="middle" width="400px"/>
        <figcaption align="middle">Caption goes here.</figcaption>
      </td>
    </tr>
    <br>
    <tr>
      <td>
        <img src="images/image3.png" align="middle" width="400px"/>
        <figcaption align="middle">Caption goes here.</figcaption>
      </td>
      <td>
        <img src="images/image4.png" align="middle" width="400px"/>
        <figcaption align="middle">Caption goes here.</figcaption>
      </td>
    </tr>
  </table>
</div> -->

<p>In task 1, we implemented a simple rasterization function that sampled at the center of each pixel. If the center of the pixel was within the triangle formed by the 3 given coordinates, we filled that pixel with the given color. Instead of checking
   every coordinate, we know that a point inside the triangle cannot have an x/y bigger than the biggest or smaller than the smallest Xi/Yi of a triangle vertex. So we can iterate from min(Xi) to max(Xi) and from min(Yi) to max(Yi), and we only check 
   within the bounding box of the triangle, which is more efficient than checking every pixel in the buffer. To figure out whether a pixel was within the triangle, we used the Point-in-Triangle: Three Line Tests as defined in lecture. This test uses a
    line equation, computed for each triangle side: Li ( x, y ) = -( x - Xi ) * ( Y(i+1) - Yi ) + ( y - Yi ) * ( X(i+1) - Xi ). And if Li is >= 0, the point is either on the line or inside the line. Naturally, if ( x, y ) is inside of all three lines (L0, L1, L2 >= 0)
     then ( x, y ) must be inside the triangle. Something we failed to understand at first was the case in which ( x, y ) is outside of all of the lines (L0, L1, L2 < 0), which is seemingly impossible. If this is the case, our triangle is “rotated” the wrong
      way since we subtracted the Xi and Yi counterclockwise, and the point must still be inside the triangle.
</p>

<p>Results after Task 1</p>
<img src="./images/screenshot_2-14_12-10-2.png" align="middle" width="400px"/>
<img src="./images/screenshot_2-14_12-21-15.png" align="middle" width="400px"/>
<img src="./images/screenshot_2-14_12-22-57.png" align="middle" width="400px"/>
<img src="./images/screenshot_2-14_12-29-13.png" align="middle" width="400px"/>

<h3 align="middle">Part 2: Antialiasing triangles</h3>

<p>Our images have aliasing after task 1, so in task 2, we use supersampling in order to get rid of jaggies. Our logic starts off similar to task 1, but we add the idea of averaging the colors inside of a pixel instead of just strictly taking or not taking
   a certain color for the entire pixel. This will prevent our image from having harsh blocks that make up the jaggies. Given a sample rate s, our algorithm divides each pixel into s subpixels and then we make the sample buffer the length of the frame buffer
    * s and then fill it with every subpixel sample. It is like we are rasterizing a higher resolution image, and we use the sample buffer to store this image. Then, in order to downsample this image into the dimensions of the framebuffer, we average out the
     colors of the s subpixels into a single pixel, like how they were originally, when we resolve to framebuffer. To average out the colors, we used the Color class to add all the subpixels’ reds, greens, and blues individually together and and then divide
      each by s. We then encountered a problem where the rectangular borders around our images became blurry as the sample rate goes up, and to solve this, we created separate fill_pixel methods for points and lines versus triangles.
</p>

<p>Results after Task 2</p>

<div align="middle">
  <table style="width=100%">
    <tr>
      <td>
        <img src="./images/screenshot_2-14_12-12-30.png" align="middle" width="400px"/>
        <figcaption align="middle">supersample rate 1 per pixel</figcaption>
      </td>
      <td>
        <img src="./images/screenshot_2-14_12-12-33.png" align="middle" width="400px"/>
        <figcaption align="middle">supersample rate 4 per pixel</figcaption>
      </td>
    </tr>
    <br>
    <tr>
      <td>
        <img src="./images/screenshot_2-14_12-12-35.png" align="middle" width="400px"/>
        <figcaption align="middle">supersample rate 9 per pixel</figcaption>
      </td>
      <td>
        <img src="./images/screenshot_2-14_12-12-37.png" align="middle" width="400px"/>
        <figcaption align="middle">supersample rate 16 per pixel</figcaption>
      </td>
    </tr>
  </table>
</div>

<div align="middle">
  <table style="width=100%">
    <tr>
      <td>
        <img src="./images/screenshot_2-14_16-27-42.png" align="middle" width="400px"/>
        <figcaption align="middle">supersample rate 1 per pixel</figcaption>
      </td>
      <td>
        <img src="./images/screenshot_2-14_16-27-46.png" align="middle" width="400px"/>
        <figcaption align="middle">supersample rate 4 per pixel</figcaption>
      </td>
    </tr>
    <br>
    <tr>
      <td>
        <img src="./images/screenshot_2-14_16-27-48.png" align="middle" width="400px"/>
        <figcaption align="middle">supersample rate 9 per pixel</figcaption>
      </td>
      <td>
        <img src="./images/screenshot_2-14_16-27-53.png" align="middle" width="400px"/>
        <figcaption align="middle">supersample rate 16 per pixel</figcaption>
      </td>
    </tr>
  </table>
</div>

<h3 align="middle">Part 3: Transforms</h3>

<p>
  We got these matrices by following the logic of matrix transformations on vectors in lecture 4. In our updated cuberman, we made him dabbing. We did this by rotating and transforming the arms, legs, body, and head. Our goal was to make the right arm look like it
   was bent at the elbow and the left arm diagonal upwards. We also made the head and body bent towards the bent arm and the knees bent to look more natural.
</p>

<p>Results</p>

<div align="middle">
  <table style="width=100%">
    <tr>
      <td>
        <img src="./images/screenshot_2-14_16-47-34.png" align="middle" width="400px"/>
        <figcaption align="middle">original cuberman</figcaption>
      </td>
      <td>
        <img src="./images/screenshot_2-14_12-14-56.png" align="middle" width="400px"/>
        <figcaption align="middle">updated/fun cuberman</figcaption>
      </td>
    </tr>
  </table>
</div>

<h2 align="middle">Section II: Sampling</h2>

<h3 align="middle">Part 4: Barycentric coordinates</h3>

<p>Barycentric coordinates use coordinates defined by ratios of a triangle instead of a universal x, y coordinate plane. ( x, y ) can be defined as alpha * A + beta * B + gamma * C. Alpha is the line equation between B and C of x and y divided by the line equation
   between B and C of xA and yA, and beta and gamma are similar. More intuitively, alpha is just how far away a point is away from the line made by B and C compared to how far A is from B and C, and thus, alpha can also be seen as how close a point is to A. For
    task 4, to figure out what color a point was, we derived and used alpha, beta, and gamma as ratios for how much color of A, B, and C to use respectively. The higher the alpha, the closer the point is to A, and so it should have more of the color at A. The below
     image is a slide from lecture that shows this relation. In this case, the distance between V and the edge between VB and VC is a lot smaller than the distance between VA and the edge between VB and VC, so alpha will be small. V is decently far from VA and should
      not have a lot of the VA color, so it makes sense to use alpha as a ratio of "how much A" we should have.
</p>

<center><img src="./images/Screenshot 2023-02-14 at 5.43.20 PM.png" align="middle" width="400px"/></center>

<p>Results</p>

<center><img src="./images/screenshot_2-14_17-40-37.png" align="middle" width="400px"/></center>

<h3 align="middle">Part 5: "Pixel sampling" for texture mapping</h3>
<p> Pixel sampling is a kind of re-sampling that samples from the existing pixels of an image in order to reconstruct new pixels to represent the image. We used it to implement texture mapping by sampling texture based on pixel sampling. Compared to the previous task, instead of using barycentric coordinates to get the new color for the pixel, we used barycentric coordinate to interpolate the u,v coordinate of the point, then used pixel sampling around that u,v coordinate to get it's color(texture). With nearest pixel sampling, we would just sampling the nearest integer texture. With bilinear pixel sampling, we carry out linear interpolations such that we intepolate the texture of the pixel using its four closest points depending on how far our point is from the four.</p>
<p> Test 5 is a good example where bilinear sampling is better. It is visible that sometimes the small pattern becomes disconnected when using nearest pixel, but it is continuous and more smooth when using bilinear sampling.</p>
<center><img src="images/bi-test5.png" align= "middle" width="400px"/></center>
<figcaption align="middle">Test 5 with Bilinear sampling, the pattern in the center is clear</figcaption>
<center><img src="images/ne-test5.png" align= "middle" width="400px"/></center>
<figcaption align="middle">Test 5 with nearest pixel sampling, the pattern in the center is sometimes discontinuous and jaggy.</figcaption>
<p> Below we compare the effects of sample per pixel and sampling method.</p>
<div align="middle">
	<table style="width=100%">
	  <tr>
		<td>
		  <img src="images/nearest-1.png" align="middle" width="400px"/>
		  <figcaption align="middle">nearest sampling at 1 sample per pixel</figcaption>
		</td>
		<td>
		  <img src="images/nearest-16.png" align="middle" width="400px"/>
		  <figcaption align="middle">nearest sampling at 16 sample per pixel</figcaption>
		</td>
	  </tr>
	  <br>
	  <tr>
		<td>
		  <img src="images/bilinear-1.png" align="middle" width="400px"/>
		  <figcaption align="middle">bilinear sampling at 1 sample per pixel</figcaption>
		</td>
		<td>
		  <img src="images/bilinear-16.png" align="middle" width="400px"/>
		  <figcaption align="middle">bilinear sampling at 16 sample per pixel</figcaption>
		</td>
	  </tr>
	</table>
  </div> 
<p> It may be visible that the image looks less jaggy when we increase sampling rate and when we use bilinear sampling. There would big a bigger difference when using bilinear sampling and nearest sampling, when the color change more frequently and when the changes don't occur at pixel boundaries, as in this case bilinear sampling will produce more average and therefore smoother results. </p>
<h3 align="middle">Part 6: "Level sampling" with mipmaps for texture mapping</h3>
<p> We understand mipmapping as pre-computing the image at different resolutions so that depending on whether the pixel is in an area with more changes in texture, we can change the resolution we want to sample from in order to choose the color for that pixel. We implemented this by calculating the “level” we should be at which is based on the rate of change of texture, then finding the corresponding texture in that level to sample on. Comparing the three methods, number of samplings is the least memory efficient method, since we would have to sample many more pixels and store them for processing, but it is very efficient for reducing anti-aliasing when there are more samples. Pixel sampling selecting is also greatly for reducing anti-alising, but it requires more computation with having to do many linear interpolations and also store many results. Level sampling is more efficient and faster as it requires less computation and storage, having many of the level at lower “resolutions”. However it may produce results that are not as efficient in anti-aliasing. </p>

<div align="middle">
	<table style="width=100%">
	  <tr>
		<td>
		  <img src="images/zero--nearest.png" align="middle" width="400px"/>
		  <figcaption align="middle">L_ZERO and P_NEAREST</figcaption>
		</td>
		<td>
		  <img src="images/zero--linear.png" align="middle" width="400px"/>
		  <figcaption align="middle">L_ZERO and P_LINEAR</figcaption>
		</td>
	  </tr>
	  <br>
	  <tr>
		<td>
		  <img src="images/nearest--nearest.png" align="middle" width="400px"/>
		  <figcaption align="middle">L_NEAREST and P_NEAREST</figcaption>
		</td>
		<td>
		  <img src="images/nearest--linear.png" align="middle" width="400px"/>
		  <figcaption align="middle">L_NEAREST and P_LINEAR</figcaption>
		</td>
	  </tr>
	</table>
  </div> 
  <p>We chose to experiment with a closeup of a cactus (source: https://www.alamy.com/stock-photo-green-cactus-with-a-lot-of-spikes-143683518.html). As its spikes can show the effects of anti-aliasing. It is visible that zero-level produces results that look a lot more clear and non-jaggy compared to the nearest level. Then, not as obviously, bilinear sampling produces less jaggy results compared to nearest pixel sampling. From these 4 images. Bilinear pixel sampling and zero-level mipmapping produced the best results in terms of clarity and smoothness of the image. </p>
  <h2 align="middle">Website link:https://nathalyspham.github.io/cs184-proj-webpages/proj1/index.html</h2>
<h2 align="middle">Section III: Art Competition</h2>
<p>If you are not participating in the optional art competition, don't worry about this section!</p>

<h3 align="middle">Part 7: Draw something interesting!</h3>

</body>
</html>
